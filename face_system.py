import cv2
import face_recognition
import sqlite3
import json
import numpy as np
import time
import warnings

# å±è”½æ— å…³ç´§è¦çš„è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="face_recognition_models")

DATABASE_NAME = "capsule_dispenser.db"

class FaceRecognizer:
    def __init__(self):
        self.known_face_encodings = []
        self.known_face_ids = []
        self.cap = None
        self.last_scan_time = 0
        self.scan_interval = 0.5  # é™åˆ¶è¯†åˆ«é¢‘ç‡ï¼Œæ¯ 0.5 ç§’ä¸€æ¬¡ï¼Œé˜²æ­¢ CPU æ»¡è½½
        
        # 1. åŠ è½½å·²çŸ¥äººè„¸
        self.load_faces_from_db()
        
        # 2. åˆå§‹åŒ–æ‘„åƒå¤´
        self.init_camera()

    def load_faces_from_db(self):
        """ä»æ•°æ®åº“åŠ è½½æ‰€æœ‰å·²å½•å…¥çš„äººè„¸ç‰¹å¾"""
        print("ğŸ‘¤ [Face] æ­£åœ¨åŠ è½½äººè„¸æ•°æ®åº“...")
        try:
            conn = sqlite3.connect(DATABASE_NAME)
            cursor = conn.cursor()
            # åªåŠ è½½æœ‰äººè„¸æ•°æ®çš„ç”¨æˆ·
            cursor.execute("SELECT user_id, name, face_encoding FROM Users WHERE face_encoding IS NOT NULL")
            rows = cursor.fetchall()
            
            self.known_face_encodings = []
            self.known_face_ids = []
            count = 0
            
            for uid, name, encoding_json in rows:
                if encoding_json:
                    try:
                        # JSON -> List -> Numpy Array
                        encoding_list = json.loads(encoding_json)
                        encoding_np = np.array(encoding_list)
                        self.known_face_encodings.append(encoding_np)
                        self.known_face_ids.append(uid)
                        count += 1
                    except Exception as e:
                        print(f"  âš ï¸ ç”¨æˆ· {name} (ID {uid}) æ•°æ®æŸå: {e}")
            
            conn.close()
            print(f"ğŸ‘¤ [Face] å·²åŠ è½½ {count} ä¸ªç”¨æˆ·çš„äººè„¸æ•°æ®")
        except Exception as e:
            print(f"âŒ [Face] æ•°æ®åº“åŠ è½½å¤±è´¥: {e}")

    def init_camera(self):
        """ä½¿ç”¨ Pi 5 å…¼å®¹ç­–ç•¥åˆå§‹åŒ–æ‘„åƒå¤´"""
        print("ğŸ“· [Face] åˆå§‹åŒ–æ‘„åƒå¤´...")
        
        # å®šä¹‰å¤šç§ GStreamer ç®¡é“å°è¯•ç­–ç•¥ (åŒ face_enroll.py)
        pipelines = [
            (
                "libcamerasrc ! video/x-raw,format=NV12,width=640,height=480,framerate=30/1 ! videoconvert ! video/x-raw,format=BGR ! appsink drop=1",
                "GStreamer (NV12 640x480)"
            ),
            (
                "libcamerasrc ! video/x-raw,width=640,height=480 ! videoconvert ! video/x-raw,format=BGR ! appsink drop=1",
                "GStreamer (Auto 640x480)"
            ),
            # å…¼å®¹é Pi 5 ç¯å¢ƒ
            (0, "V4L2 Index 0") 
        ]

        for source, name in pipelines:
            try:
                if isinstance(source, int):
                    self.cap = cv2.VideoCapture(source)
                else:
                    self.cap = cv2.VideoCapture(source, cv2.CAP_GSTREAMER)
                
                if self.cap.isOpened():
                    # å°è¯•è¯»ä¸€å¸§
                    ret, _ = self.cap.read()
                    if ret:
                        print(f"âœ… [Face] æ‘„åƒå¤´å°±ç»ª: {name}")
                        return
                    else:
                        self.cap.release()
            except Exception:
                pass
        
        print("âŒ [Face] æ— æ³•åˆå§‹åŒ–ä»»ä½•æ‘„åƒå¤´ï¼Œäººè„¸è¯†åˆ«å°†ä¸å¯ç”¨")
        self.cap = None

    def scan(self):
        """
        å°è¯•è¯»å–ä¸€å¸§å¹¶è¯†åˆ«ã€‚
        è¿”å›: matched_user_id (int) æˆ– None
        """
        # å¦‚æœæ²¡æ‘„åƒå¤´æˆ–æ²¡äººè„¸åº“ï¼Œç›´æ¥è·³è¿‡
        if not self.cap or not self.known_face_encodings:
            return None

        # é¢‘ç‡æ§åˆ¶
        if time.time() - self.last_scan_time < self.scan_interval:
            return None
        self.last_scan_time = time.time()

        ret, frame = self.cap.read()
        if not ret:
            print("âš ï¸ [Face] æ— æ³•è¯»å–è§†é¢‘å¸§")
            return None

        # 1. å›¾åƒé¢„å¤„ç†
        small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)
        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

        # 2. æ£€æµ‹äººè„¸
        face_locations = face_recognition.face_locations(rgb_small_frame)
        if not face_locations:
            # æ²¡äººè„¸æ—¶ä¿æŒé™é»˜ï¼Œä»¥å…åˆ·å±
            return None 

        # 3. æå–ç‰¹å¾
        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)
        
        # print(f"ğŸ‘€ [Face] æ£€æµ‹åˆ° {len(face_encodings)} å¼ äººè„¸ï¼Œæ­£åœ¨åˆ†æ...")

        # 4. æ¯”å¯¹
        for face_encoding in face_encodings:
            # è®¡ç®—ä¸æ•°æ®åº“ä¸­æ‰€æœ‰äººè„¸çš„æ¬§æ°è·ç¦»
            # è·ç¦»è¶Šå°è¶Šç›¸ä¼¼ã€‚é€šå¸¸ 0.6 æ˜¯åˆ†ç•Œçº¿ã€‚
            face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)
            
            # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„é‚£ä¸ª
            best_match_index = np.argmin(face_distances)
            min_distance = face_distances[best_match_index]

            if min_distance < 0.6: # æ”¾å®½é˜ˆå€¼åˆ° 0.6
                user_id = self.known_face_ids[best_match_index]
                print(f"ğŸ‘¤ [Face] è¯†åˆ«æˆåŠŸ! ID: {user_id} (è·ç¦»: {min_distance:.2f})")
                return user_id
            else:
                pass
                # print(f"ğŸ¤” [Face] æœªçŸ¥ç”¨æˆ· (æœ€è¿‘è·ç¦»: {min_distance:.2f})")
        
        return None

    def close(self):
        if self.cap:
            self.cap.release()
